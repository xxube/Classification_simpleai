{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(X_test):\n",
        "    Y_val = model.forward(data)\n",
        "\n",
        "    if Y_test[i] == 0:\n",
        "      flower_type = 'Setosa'\n",
        "    elif Y_test[i] == 1:\n",
        "      flower_type = 'Versiolor'\n",
        "    else:\n",
        "      flower_type = 'Virginica'\n",
        "\n",
        "# Will tell us what type of flower our network think it is\n",
        "    print(f'{i+1}.)  {str(Y_val)} \\t {flower_type}  \\t  {Y_val.argmax().item()}')\n",
        "\n",
        "# Correct or not\n",
        "    if Y_val.argmax().item() == Y_test[i]:\n",
        "      correct += 1\n",
        "\n",
        "print(f'We got {correct} correct!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t59mrlFW7grB",
        "outputId": "7f5b3291-1349-406f-ba42-ed80eabaf7f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.)  tensor([-2.7797,  4.5314, -1.4912]) \t Versiolor  \t  1\n",
            "2.)  tensor([-4.4013,  4.7417,  0.4829]) \t Versiolor  \t  1\n",
            "3.)  tensor([-4.3954,  4.5395,  0.6904]) \t Versiolor  \t  1\n",
            "4.)  tensor([  6.5936,   0.3608, -11.7499]) \t Setosa  \t  0\n",
            "5.)  tensor([-3.3163,  4.8289, -1.1195]) \t Versiolor  \t  1\n",
            "6.)  tensor([-2.3890,  4.2909, -1.7372]) \t Versiolor  \t  1\n",
            "7.)  tensor([  6.2607,   0.3110, -11.0161]) \t Setosa  \t  0\n",
            "8.)  tensor([  7.0480,   0.2745, -12.4800]) \t Setosa  \t  0\n",
            "9.)  tensor([ 5.5561,  0.3588, -9.7423]) \t Setosa  \t  0\n",
            "10.)  tensor([-7.7970,  4.2159,  5.3954]) \t Virginica  \t  2\n",
            "11.)  tensor([-8.2547,  3.6327,  6.6057]) \t Virginica  \t  2\n",
            "12.)  tensor([-8.0261,  3.8950,  6.0090]) \t Virginica  \t  2\n",
            "13.)  tensor([  6.0427,   0.3212, -10.6109]) \t Setosa  \t  0\n",
            "14.)  tensor([-6.2912,  3.8178,  3.8877]) \t Virginica  \t  2\n",
            "15.)  tensor([-8.7504,  2.8818,  8.0549]) \t Virginica  \t  2\n",
            "16.)  tensor([ 5.3819,  0.3722, -9.4180]) \t Setosa  \t  0\n",
            "17.)  tensor([-2.2870,  4.0017, -1.4548]) \t Versiolor  \t  1\n",
            "18.)  tensor([-6.4728,  3.7190,  4.2467]) \t Versiolor  \t  2\n",
            "19.)  tensor([-10.5063,   3.5000,   9.6384]) \t Virginica  \t  2\n",
            "20.)  tensor([-12.1391,   3.2749,  11.9629]) \t Virginica  \t  2\n",
            "21.)  tensor([  6.2958,   0.3094, -11.0814]) \t Setosa  \t  0\n",
            "22.)  tensor([-4.0501,  4.4404,  0.3657]) \t Versiolor  \t  1\n",
            "23.)  tensor([-4.5541,  4.3339,  1.1182]) \t Versiolor  \t  1\n",
            "24.)  tensor([-6.5402,  3.8167,  4.2081]) \t Virginica  \t  2\n",
            "25.)  tensor([-4.5090,  4.0783,  1.3314]) \t Versiolor  \t  1\n",
            "26.)  tensor([-10.7529,   3.6534,   9.7513]) \t Virginica  \t  2\n",
            "27.)  tensor([  6.4484,   0.3023, -11.3652]) \t Setosa  \t  0\n",
            "28.)  tensor([ 4.7418,  0.5311, -8.4552]) \t Setosa  \t  0\n",
            "29.)  tensor([-8.5665,  3.1516,  7.5471]) \t Virginica  \t  2\n",
            "30.)  tensor([-7.9406,  3.6716,  6.1536]) \t Virginica  \t  2\n",
            "We got 29 correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_flower = torch.tensor([6.5, 3.4, 7.2, 5.1])\n",
        "with torch.no_grad():\n",
        "  print(model(new_flower))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofjag_Ln3Rs1",
        "outputId": "3c3e5c38-e8f6-459f-a03f-f5e03951f1ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-19.7870,   2.2631,  22.9279])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save our NN model\n",
        "torch.save(model.state_dict(), 'Simple2layersNN.pt')"
      ],
      "metadata": {
        "id": "LnKHp4mr4PGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "new_model = flower_model()\n",
        "new_model.load_state_dict(torch.load('Simple2layersNN.pt'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsZ_HhbP47bP",
        "outputId": "e9f825fc-d1e9-4148-85f9-15bde30bd722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chck if it loaded correctly\n",
        "new_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVyp3EAB7n3o",
        "outputId": "b26d6b29-fec6-4008-bab8-321393f50a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "flower_model(\n",
              "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
              "  (fc2): Linear(in_features=8, out_features=9, bias=True)\n",
              "  (out): Linear(in_features=9, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    }
  ]
}